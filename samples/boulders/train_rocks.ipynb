{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from PIL import Image\n",
    "\n",
    "# Корневая папка проекта\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "# Путь папки с изображениями\n",
    "IMAGES_DIR = \"./images\"\n",
    "\n",
    "# Загружаем библиотеки алгоритма Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # Чтоб находить файлы библиотеки\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "\n",
    "#%matplotlib inline \n",
    "\n",
    "# Сюда сохраняем логи и обученную модель\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Путь до файла с весами\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Загружаем веса, если необходимо\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Настройки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RocksConfig(Config):\n",
    "    \"\"\"Конфигурация для обучения на датасете камней\n",
    "    \"\"\"\n",
    "    NAME = \"rocks\"\n",
    "\n",
    "    # При запуске на CPU нужно указывать GPU_COUNT = 1. Изображения\n",
    "    # не самые маленькие, поэтому всего 2 изображения за раз. \n",
    "    # 12GB GPU может обрабатывать 2 изображения 1024x1024px.\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    # Количество классов (включая задний фон)\n",
    "    NUM_CLASSES = 1 + 1  # фон + камень\n",
    "\n",
    "    # Изображения увеличиваются по меньшей стороне до IMAGE_MIN_DIM\n",
    "    # так, чтоб большая сторона не превысила IMAGE_MAX_DIM. Затем\n",
    "    # добиваются нулями до квадрата.\n",
    "    IMAGE_RESIZE_MODE = \"square\"\n",
    "    IMAGE_MIN_DIM = 320\n",
    "    IMAGE_MAX_DIM = 448\n",
    "    \n",
    "config = RocksConfig()\n",
    "# config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Этот класс загружает изображения и маски датасета\n",
    "#Для использования переопределяются load_image,\n",
    "#load_mask, image_reference\n",
    "class RocksDataset(utils.Dataset):\n",
    "\n",
    "    #перечисляет изображения в images/ и сохраняет информацию о них\n",
    "    def load_images(self, startId, count):\n",
    "        # Add classes\n",
    "        self.add_class(\"rocks\", 1, \"rock\")\n",
    "        lastId = startId + count;\n",
    "        for file in os.listdir(IMAGES_DIR):\n",
    "            match = re.match(\"^(\\d+)\\.png$\", file)\n",
    "            if match:\n",
    "                image_id = int(match.group(1))\n",
    "                if image_id >= startId <= lastId:\n",
    "                    self.add_image(\"rocks\", image_id=int(match.group(1)), \n",
    "                                   path=f\"{IMAGES_DIR}/{file}\")\n",
    "\n",
    "    #загружает изображение в виде массива numpy\n",
    "    def load_image(self, image_id):\n",
    "        print(f\"Asked to find image at {image_id}\")\n",
    "        path = self.image_reference(image_id)[\"path\"]\n",
    "        return self.load_png_as_nparray(path)\n",
    "    \n",
    "    #загружает маску в виде кортежа. первый элемент - массив boolean\n",
    "    #формы width/height/masks_num, второй - массив с номерами классов каждой маски\n",
    "    #размера masks_num\n",
    "    def load_mask(self, index):\n",
    "        print(f\"Asked to find mask at {index}\")\n",
    "        mask = self.get_mask(index)\n",
    "        if mask:\n",
    "            return mask;\n",
    "        masks = []\n",
    "        class_ids = []\n",
    "        for file in os.listdir(IMAGES_DIR):\n",
    "            match = re.match(f\"^{index}_mask_(\\d+)_(\\d+)\\.png$\", file)\n",
    "            if match:\n",
    "                mask_img, w, h = self.load_png(f\"{IMAGES_DIR}/{file}\")\n",
    "                bool_mask = self.pixels_to_mask(mask_img)\n",
    "                bool_mask = bool_mask.reshape(h, w)\n",
    "                masks.append(bool_mask)\n",
    "                class_ids.append(int(match.group(1)))\n",
    "        merged_mask = np.stack(masks, axis=2)\n",
    "        masks_num = merged_mask.shape[2]\n",
    "        mask = (merged_mask, np.array(class_ids))\n",
    "        self.save_mask(index, mask)\n",
    "        return mask\n",
    "    \n",
    "    #кэш масок. загружает маску из памяти, или с диска\n",
    "    #если не нашли - собираем заново из изображений\n",
    "    #в images/\n",
    "    def get_mask(self, index):\n",
    "        try:\n",
    "            try:\n",
    "                return self._masks[index]\n",
    "            except AttributeError:\n",
    "                self._masks = {};\n",
    "            except KeyError:\n",
    "                print(\"loading mask from disk\")\n",
    "            serialized = open(f\"{MODEL_DIR}/{index}.mask\", \"rb\").read()\n",
    "            mask = pickle.loads(serialized)\n",
    "            self._masks[index] = mask\n",
    "            return mask\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    #сериализует маску на диск, чтоб не собирать при новом прогоне\n",
    "    def save_mask(self, index, mask):\n",
    "        serialized = pickle.dumps(mask)\n",
    "        open(f\"{MODEL_DIR}/{index}.mask\", \"wb\").write(serialized)\n",
    "        try:\n",
    "            self._masks[index] = mask\n",
    "        except AttributeError:\n",
    "            self._masks = {};\n",
    "\n",
    "    #возвращает информацию об изображении\n",
    "    def image_reference(self, image_id):\n",
    "        #print(f\"Asked for an image reference at {image_id}\")\n",
    "        \"\"\"Return the shapes data of the image.\"\"\"\n",
    "        for info in self.image_info:\n",
    "            if info[\"id\"] == image_id:\n",
    "                return info;\n",
    "        super(self.__class__, self).image_reference(image_id)\n",
    "\n",
    "    def load_png_as_nparray(self, path):\n",
    "#         print(path)\n",
    "        image = Image.open(path)\n",
    "        w, h = image.size\n",
    "        return np.array(image.getdata()).reshape(h, w, 3).astype(np.uint8)\n",
    "    \n",
    "    def load_png(self, path):\n",
    "        print(path)\n",
    "        image = Image.open(path)\n",
    "        w, h = image.size\n",
    "        return (np.array(image.getdata()).astype(np.uint8), w, h)\n",
    "        \n",
    "    def image_to_mask(self, img):\n",
    "        x, y, z = img.shape\n",
    "        reshaped = img.reshape(x * y, z)\n",
    "        to_bool = lambda p: False if any(v > 0 for v in p) else True\n",
    "        img = np.array([to_bool(pixel) for pixel in reshaped])\n",
    "        return img.reshape(x, y)\n",
    "    \n",
    "    def pixels_to_mask(self, img):\n",
    "        to_bool = lambda p: False if any(v > 0 for v in p) else True\n",
    "        return np.array([to_bool(pixel) for pixel in img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#набор для обучения\n",
    "dataset_train = RocksDataset()\n",
    "dataset_train.load_images(0, 50)\n",
    "dataset_train.prepare()\n",
    "\n",
    "#набор для оценки\n",
    "dataset_val = RocksDataset()\n",
    "dataset_val.load_images(50, 16)\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "It looks like you are subclassing `Model` and you forgot to call `super(YourClass, self).__init__()`. Always start with this line.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\albem\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m    306\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m                 \u001b[0mis_graph_network\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Stuff\\dev\\image-recog\\Mask_RCNN\\mrcnn\\parallel_model.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[1;34m(self, attrname)\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minner_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParallelModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattrname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ParallelModel' object has no attribute '_is_graph_network'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-22388218a259>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Создаём модель в режиме обучения\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m model = modellib.MaskRCNN(mode=\"training\", config=config,\n\u001b[1;32m----> 3\u001b[1;33m                           model_dir=MODEL_DIR)\n\u001b[0m",
      "\u001b[1;32mC:\\Stuff\\dev\\image-recog\\Mask_RCNN\\mrcnn\\model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, mode, config, model_dir)\u001b[0m\n\u001b[0;32m   1836\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1837\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_log_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1838\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1839\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1840\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Stuff\\dev\\image-recog\\Mask_RCNN\\mrcnn\\model.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, mode, config)\u001b[0m\n\u001b[0;32m   2061\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGPU_COUNT\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2062\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[0mmrcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparallel_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mParallelModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2063\u001b[1;33m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParallelModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGPU_COUNT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2064\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2065\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Stuff\\dev\\image-recog\\Mask_RCNN\\mrcnn\\parallel_model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, keras_model, gpu_count)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mgpu_count\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mNumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mGPUs\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mMust\u001b[0m \u001b[0mbe\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \"\"\"\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minner_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgpu_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgpu_count\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mmerged_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_parallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\albem\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m    308\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m                 raise RuntimeError(\n\u001b[1;32m--> 310\u001b[1;33m                     \u001b[1;34m'It looks like you are subclassing `Model` and you '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    311\u001b[0m                     \u001b[1;34m'forgot to call `super(YourClass, self).__init__()`.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m                     ' Always start with this line.')\n",
      "\u001b[1;31mRuntimeError\u001b[0m: It looks like you are subclassing `Model` and you forgot to call `super(YourClass, self).__init__()`. Always start with this line."
     ]
    }
   ],
   "source": [
    "# Создаём модель в режиме обучения\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Веса для начала обучения\n",
    "init_with = \"coco\"  # imagenet, coco, или last\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Загружаем веса, обученные на базе COCO, но пропускаем\n",
    "    # слои, отличные по количеству классов.\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    # загружаем последнюю обученную модель и продолжаем обучение\n",
    "    model.load_weights(model.find_last(), by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение\n",
    "\n",
    "Train in two stages:\n",
    "1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, pass `layers='heads'` to the `train()` function.\n",
    "\n",
    "2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. Simply pass `layers=\"all` to train all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем головные ветки\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=1, \n",
    "            layers='heads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тонкая настройка всех слоёв\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE / 10,\n",
    "            epochs=2, \n",
    "            layers=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обнаружение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(ShapesConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "# Пересоздаём модель в режиме обнаружения\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Путь до сохранённых весов\n",
    "model_path = model.find_last()\n",
    "\n",
    "# Загружаем обученные веса\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестируем на случайном изображении\n",
    "image_id = random.choice(dataset_val.image_ids)\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset_val, inference_config, \n",
    "                           image_id, use_mini_mask=False)\n",
    "\n",
    "log(\"original_image\", original_image)\n",
    "log(\"image_meta\", image_meta)\n",
    "log(\"gt_class_id\", gt_class_id)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)\n",
    "\n",
    "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                            dataset_train.class_names, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.detect([original_image], verbose=1)\n",
    "\n",
    "r = results[0]\n",
    "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_val.class_names, r['scores'], ax=get_ax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычисляем VOC-Style mAP @ IoU=0.5\n",
    "# Тестируем на 10 изображениях\n",
    "image_ids = np.random.choice(dataset_val.image_ids, 10)\n",
    "APs = []\n",
    "for image_id in image_ids:\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset_val, inference_config,\n",
    "                               image_id, use_mini_mask=False)\n",
    "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
    "    # Обнаружение объекта\n",
    "    results = model.detect([image], verbose=0)\n",
    "    r = results[0]\n",
    "    # Вычисляем AP\n",
    "    AP, precisions, recalls, overlaps =\\\n",
    "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "    APs.append(AP)\n",
    "    \n",
    "print(\"mAP: \", np.mean(APs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
