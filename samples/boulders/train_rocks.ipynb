{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from PIL import Image\n",
    "\n",
    "# Корневая папка проекта\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "# Путь папки с изображениями\n",
    "IMAGES_DIR = \"./images\"\n",
    "\n",
    "# Загружаем библиотеки алгоритма Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # Чтоб находить файлы библиотеки\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "\n",
    "#%matplotlib inline \n",
    "\n",
    "# Сюда сохраняем логи и обученную модель\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Путь до файла с весами\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Загружаем веса, если необходимо\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Настройки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RocksConfig(Config):\n",
    "    \"\"\"Конфигурация для обучения на датасете камней\n",
    "    \"\"\"\n",
    "    NAME = \"rocks\"\n",
    "\n",
    "    # При запуске на CPU нужно указывать GPU_COUNT = 1. Изображения\n",
    "    # не самые маленькие, поэтому всего 2 изображения за раз. \n",
    "    # 12GB GPU может обрабатывать 2 изображения 1024x1024px.\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    # Количество классов (включая задний фон)\n",
    "    NUM_CLASSES = 1 + 1  # фон + камень\n",
    "\n",
    "    # Изображения увеличиваются по меньшей стороне до IMAGE_MIN_DIM\n",
    "    # так, чтоб большая сторона не превысила IMAGE_MAX_DIM. Затем\n",
    "    # добиваются нулями до квадрата.\n",
    "    IMAGE_RESIZE_MODE = \"square\"\n",
    "    IMAGE_MIN_DIM = 320\n",
    "    IMAGE_MAX_DIM = 448\n",
    "    \n",
    "config = RocksConfig()\n",
    "# config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Этот класс загружает изображения и маски датасета\n",
    "#Для использования переопределяются load_image,\n",
    "#load_mask, image_reference\n",
    "class RocksDataset(utils.Dataset):\n",
    "    \n",
    "    #перечисляет изображения в images/ и сохраняет информацию о них\n",
    "    def load_images(self, start_id, count):\n",
    "        # Add classes\n",
    "        self.add_class(\"rocks\", 1, \"rock\")\n",
    "        \n",
    "        last_id = start_id + count - 1;\n",
    "        \n",
    "        model_id = 0\n",
    "        for file in os.listdir(IMAGES_DIR):\n",
    "            match = re.match(\"^(\\d+)\\.png$\", file)\n",
    "            if match:\n",
    "                image_id = int(match.group(1))\n",
    "                if image_id >= start_id and image_id <= last_id:\n",
    "                    self.add_image(\"rocks\", image_id=model_id,\n",
    "                                   real_image_id=int(match.group(1)), \n",
    "                                   path=f\"{IMAGES_DIR}/{file}\")\n",
    "                    print(f\"Add image {image_id} with id {model_id}\")\n",
    "                    model_id += 1\n",
    "\n",
    "    #загружает изображение в виде массива numpy\n",
    "    def load_image(self, image_id):\n",
    "        print(f\"Asked to find image at {image_id}\")\n",
    "        path = self.image_reference(image_id)[\"path\"]\n",
    "        return self.load_png_as_nparray(path)\n",
    "    \n",
    "    #загружает маску в виде кортежа. первый элемент - массив boolean\n",
    "    #формы width/height/masks_num, второй - массив с номерами классов каждой маски\n",
    "    #размера masks_num\n",
    "    def load_mask(self, index):\n",
    "        print(f\"Asked to find mask at {index}\")\n",
    "        index = self.image_reference(index)[\"real_image_id\"]\n",
    "        mask = self.get_mask(index)\n",
    "        if mask:\n",
    "            return mask;\n",
    "        masks = []\n",
    "        class_ids = []\n",
    "        for file in os.listdir(IMAGES_DIR):\n",
    "            match = re.match(f\"^{index}_mask_(\\d+)_(\\d+)\\.png$\", file)\n",
    "            if match:\n",
    "                mask_img, w, h = self.load_png(f\"{IMAGES_DIR}/{file}\")\n",
    "                bool_mask = self.pixels_to_mask(mask_img)\n",
    "                bool_mask = bool_mask.reshape(h, w)\n",
    "                masks.append(bool_mask)\n",
    "                class_ids.append(int(match.group(1)))\n",
    "        merged_mask = np.stack(masks, axis=2)\n",
    "        masks_num = merged_mask.shape[2]\n",
    "        mask = (merged_mask, np.array(class_ids))\n",
    "        self.save_mask(index, mask)\n",
    "        return mask\n",
    "    \n",
    "    #кэш масок. загружает маску из памяти, или с диска\n",
    "    #если не нашли - собираем заново из изображений\n",
    "    #в images/\n",
    "    def get_mask(self, index):\n",
    "        try:\n",
    "            try:\n",
    "                return self._masks[index]\n",
    "            except AttributeError:\n",
    "                self._masks = {};\n",
    "            except KeyError:\n",
    "                print(\"loading mask from disk\")\n",
    "            serialized = open(f\"{MODEL_DIR}/{index}.mask\", \"rb\").read()\n",
    "            mask = pickle.loads(serialized)\n",
    "            self._masks[index] = mask\n",
    "            return mask\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    #сериализует маску на диск, чтоб не собирать при новом прогоне\n",
    "    def save_mask(self, index, mask):\n",
    "        serialized = pickle.dumps(mask)\n",
    "        open(f\"{MODEL_DIR}/{index}.mask\", \"wb\").write(serialized)\n",
    "        try:\n",
    "            self._masks[index] = mask\n",
    "        except AttributeError:\n",
    "            self._masks = {};\n",
    "\n",
    "    #возвращает информацию об изображении\n",
    "    def image_reference(self, image_id):\n",
    "        #print(f\"Asked for an image reference at {image_id}\")\n",
    "        \"\"\"Return the shapes data of the image.\"\"\"\n",
    "        for info in self.image_info:\n",
    "            if info[\"id\"] == image_id:\n",
    "                return info;\n",
    "        super(self.__class__, self).image_reference(image_id)\n",
    "\n",
    "    def load_png_as_nparray(self, path):\n",
    "#         print(path)\n",
    "        image = Image.open(path)\n",
    "        w, h = image.size\n",
    "        return np.array(image.getdata()).reshape(h, w, 3).astype(np.uint8)\n",
    "    \n",
    "    def load_png(self, path):\n",
    "        print(path)\n",
    "        image = Image.open(path)\n",
    "        w, h = image.size\n",
    "        return (np.array(image.getdata()).astype(np.uint8), w, h)\n",
    "        \n",
    "    def image_to_mask(self, img):\n",
    "        x, y, z = img.shape\n",
    "        reshaped = img.reshape(x * y, z)\n",
    "        to_bool = lambda p: False if any(v > 0 for v in p) else True\n",
    "        img = np.array([to_bool(pixel) for pixel in reshaped])\n",
    "        return img.reshape(x, y)\n",
    "    \n",
    "    def pixels_to_mask(self, img):\n",
    "        to_bool = lambda p: False if any(v > 0 for v in p) else True\n",
    "        return np.array([to_bool(pixel) for pixel in img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add image 0 with id 0\n",
      "Add image 1 with id 1\n",
      "Add image 10 with id 2\n",
      "Add image 11 with id 3\n",
      "Add image 12 with id 4\n",
      "Add image 13 with id 5\n",
      "Add image 14 with id 6\n",
      "Add image 15 with id 7\n",
      "Add image 16 with id 8\n",
      "Add image 17 with id 9\n",
      "Add image 18 with id 10\n",
      "Add image 19 with id 11\n",
      "Add image 2 with id 12\n",
      "Add image 20 with id 13\n",
      "Add image 21 with id 14\n",
      "Add image 22 with id 15\n",
      "Add image 23 with id 16\n",
      "Add image 24 with id 17\n",
      "Add image 25 with id 18\n",
      "Add image 26 with id 19\n",
      "Add image 27 with id 20\n",
      "Add image 28 with id 21\n",
      "Add image 29 with id 22\n",
      "Add image 3 with id 23\n",
      "Add image 30 with id 24\n",
      "Add image 31 with id 25\n",
      "Add image 32 with id 26\n",
      "Add image 33 with id 27\n",
      "Add image 34 with id 28\n",
      "Add image 35 with id 29\n",
      "Add image 36 with id 30\n",
      "Add image 37 with id 31\n",
      "Add image 38 with id 32\n",
      "Add image 39 with id 33\n",
      "Add image 4 with id 34\n",
      "Add image 40 with id 35\n",
      "Add image 41 with id 36\n",
      "Add image 42 with id 37\n",
      "Add image 43 with id 38\n",
      "Add image 44 with id 39\n",
      "Add image 45 with id 40\n",
      "Add image 46 with id 41\n",
      "Add image 47 with id 42\n",
      "Add image 48 with id 43\n",
      "Add image 49 with id 44\n",
      "Add image 5 with id 45\n",
      "Add image 50 with id 46\n",
      "Add image 51 with id 47\n",
      "Add image 52 with id 48\n",
      "Add image 53 with id 49\n",
      "Add image 54 with id 50\n",
      "Add image 55 with id 51\n",
      "Add image 56 with id 52\n",
      "Add image 57 with id 53\n",
      "Add image 58 with id 54\n",
      "Add image 59 with id 55\n",
      "Add image 6 with id 56\n",
      "Add image 7 with id 57\n",
      "Add image 8 with id 58\n",
      "Add image 9 with id 59\n",
      "Add image 60 with id 0\n",
      "Add image 61 with id 1\n",
      "Add image 62 with id 2\n"
     ]
    }
   ],
   "source": [
    "#набор для обучения\n",
    "dataset_train = RocksDataset()\n",
    "dataset_train.load_images(0, 60)\n",
    "dataset_train.prepare()\n",
    "\n",
    "#набор для оценки\n",
    "dataset_val = RocksDataset()\n",
    "dataset_val.load_images(60, 3)\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "It looks like you are subclassing `Model` and you forgot to call `super(YourClass, self).__init__()`. Always start with this line.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\albem\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m    306\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m                 \u001b[0mis_graph_network\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Stuff\\dev\\image-recog\\Mask_RCNN\\mrcnn\\parallel_model.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[1;34m(self, attrname)\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minner_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParallelModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattrname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ParallelModel' object has no attribute '_is_graph_network'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-22388218a259>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Создаём модель в режиме обучения\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m model = modellib.MaskRCNN(mode=\"training\", config=config,\n\u001b[1;32m----> 3\u001b[1;33m                           model_dir=MODEL_DIR)\n\u001b[0m",
      "\u001b[1;32mC:\\Stuff\\dev\\image-recog\\Mask_RCNN\\mrcnn\\model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, mode, config, model_dir)\u001b[0m\n\u001b[0;32m   1836\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1837\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_log_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1838\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1839\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1840\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Stuff\\dev\\image-recog\\Mask_RCNN\\mrcnn\\model.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, mode, config)\u001b[0m\n\u001b[0;32m   2061\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGPU_COUNT\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2062\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[0mmrcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparallel_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mParallelModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2063\u001b[1;33m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParallelModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGPU_COUNT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2064\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2065\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Stuff\\dev\\image-recog\\Mask_RCNN\\mrcnn\\parallel_model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, keras_model, gpu_count)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mgpu_count\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mNumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mGPUs\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mMust\u001b[0m \u001b[0mbe\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \"\"\"\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minner_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgpu_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgpu_count\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mmerged_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_parallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\albem\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m    308\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m                 raise RuntimeError(\n\u001b[1;32m--> 310\u001b[1;33m                     \u001b[1;34m'It looks like you are subclassing `Model` and you '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    311\u001b[0m                     \u001b[1;34m'forgot to call `super(YourClass, self).__init__()`.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m                     ' Always start with this line.')\n",
      "\u001b[1;31mRuntimeError\u001b[0m: It looks like you are subclassing `Model` and you forgot to call `super(YourClass, self).__init__()`. Always start with this line."
     ]
    }
   ],
   "source": [
    "# Создаём модель в режиме обучения\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Веса для начала обучения\n",
    "init_with = \"coco\"  # imagenet, coco, или last\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Загружаем веса, обученные на базе COCO, но пропускаем\n",
    "    # слои, отличные по количеству классов.\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    # загружаем последнюю обученную модель и продолжаем обучение\n",
    "    model.load_weights(model.find_last(), by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение\n",
    "\n",
    "Train in two stages:\n",
    "1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, pass `layers='heads'` to the `train()` function.\n",
    "\n",
    "2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. Simply pass `layers=\"all` to train all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем головные ветки\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=1, \n",
    "            layers='heads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тонкая настройка всех слоёв\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE / 10,\n",
    "            epochs=2, \n",
    "            layers=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обнаружение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(ShapesConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "# Пересоздаём модель в режиме обнаружения\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Путь до сохранённых весов\n",
    "model_path = model.find_last()\n",
    "\n",
    "# Загружаем обученные веса\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестируем на случайном изображении\n",
    "image_id = random.choice(dataset_val.image_ids)\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset_val, inference_config, \n",
    "                           image_id, use_mini_mask=False)\n",
    "\n",
    "log(\"original_image\", original_image)\n",
    "log(\"image_meta\", image_meta)\n",
    "log(\"gt_class_id\", gt_class_id)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)\n",
    "\n",
    "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                            dataset_train.class_names, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.detect([original_image], verbose=1)\n",
    "\n",
    "r = results[0]\n",
    "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_val.class_names, r['scores'], ax=get_ax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычисляем VOC-Style mAP @ IoU=0.5\n",
    "# Тестируем на 10 изображениях\n",
    "image_ids = np.random.choice(dataset_val.image_ids, 10)\n",
    "APs = []\n",
    "for image_id in image_ids:\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset_val, inference_config,\n",
    "                               image_id, use_mini_mask=False)\n",
    "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
    "    # Обнаружение объекта\n",
    "    results = model.detect([image], verbose=0)\n",
    "    r = results[0]\n",
    "    # Вычисляем AP\n",
    "    AP, precisions, recalls, overlaps =\\\n",
    "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "    APs.append(AP)\n",
    "    \n",
    "print(\"mAP: \", np.mean(APs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
